{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import shortuuid\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(self, data):\n",
    "        # Add something to the component's data\n",
    "        self.data.append(data)\n",
    "\n",
    "def to_disk(self, path, exclude=tuple()):    # This will receive the directory path + /my_component   \n",
    "    data_path = path / \"data.json\"        \n",
    "    with data_path.open(\"w\", encoding=\"utf8\") as f:            \n",
    "        f.write(json.dumps(self.data))\n",
    "\n",
    "def from_disk(self, path, exclude=tuple()):        # This will receive the directory path + /my_component       \n",
    "    data_path = path / \"data.json\"        \n",
    "    with data_path.open(\"r\", encoding=\"utf8\") as f:            \n",
    "        self.data = json.loads(f)        \n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in files from folder: 0_CIADirectorMikePompeoMeetingNorthKorea\n",
      "Executing code for  test_parsing_no_annotations/0_CIADirectorMikePompeoMeetingNorthKorea\\0_L.json\n",
      "Executing code for  test_parsing_no_annotations/0_CIADirectorMikePompeoMeetingNorthKorea\\0_LL.json\n",
      "Executing code for  test_parsing_no_annotations/0_CIADirectorMikePompeoMeetingNorthKorea\\0_M.json\n",
      "Executing code for  test_parsing_no_annotations/0_CIADirectorMikePompeoMeetingNorthKorea\\0_R.json\n",
      "Executing code for  test_parsing_no_annotations/0_CIADirectorMikePompeoMeetingNorthKorea\\0_RR.json\n",
      "Reading in files from folder: 1_ComeyMemo\n",
      "Executing code for  test_parsing_no_annotations/1_ComeyMemo\\1_L.json\n",
      "Executing code for  test_parsing_no_annotations/1_ComeyMemo\\1_LL.json\n",
      "Executing code for  test_parsing_no_annotations/1_ComeyMemo\\1_M.json\n",
      "Executing code for  test_parsing_no_annotations/1_ComeyMemo\\1_R.json\n",
      "Executing code for  test_parsing_no_annotations/1_ComeyMemo\\1_RR.json\n",
      "Reading in files from folder: 2_NorthKoreaNuclearStopAnnouncement\n",
      "Executing code for  test_parsing_no_annotations/2_NorthKoreaNuclearStopAnnouncement\\2_L.json\n",
      "Executing code for  test_parsing_no_annotations/2_NorthKoreaNuclearStopAnnouncement\\2_LL.json\n",
      "Executing code for  test_parsing_no_annotations/2_NorthKoreaNuclearStopAnnouncement\\2_M.json\n",
      "Executing code for  test_parsing_no_annotations/2_NorthKoreaNuclearStopAnnouncement\\2_R.json\n",
      "Executing code for  test_parsing_no_annotations/2_NorthKoreaNuclearStopAnnouncement\\2_RR.json\n",
      "Reading in files from folder: 3_DemocratsSueRUTrump\n",
      "Executing code for  test_parsing_no_annotations/3_DemocratsSueRUTrump\\3_L.json\n",
      "Executing code for  test_parsing_no_annotations/3_DemocratsSueRUTrump\\3_LL.json\n",
      "Executing code for  test_parsing_no_annotations/3_DemocratsSueRUTrump\\3_M.json\n",
      "Executing code for  test_parsing_no_annotations/3_DemocratsSueRUTrump\\3_R.json\n",
      "Executing code for  test_parsing_no_annotations/3_DemocratsSueRUTrump\\3_RR.json\n",
      "Reading in files from folder: 4_TrumpDealIran\n",
      "Executing code for  test_parsing_no_annotations/4_TrumpDealIran\\4_L.json\n",
      "Executing code for  test_parsing_no_annotations/4_TrumpDealIran\\4_LL.json\n",
      "Executing code for  test_parsing_no_annotations/4_TrumpDealIran\\4_M.json\n",
      "Executing code for  test_parsing_no_annotations/4_TrumpDealIran\\4_R.json\n",
      "Executing code for  test_parsing_no_annotations/4_TrumpDealIran\\4_RR.json\n",
      "Reading in files from folder: 5_TrumpVisitUnitedKingdom\n",
      "Executing code for  test_parsing_no_annotations/5_TrumpVisitUnitedKingdom\\5_L.json\n",
      "Executing code for  test_parsing_no_annotations/5_TrumpVisitUnitedKingdom\\5_LL.json\n",
      "Executing code for  test_parsing_no_annotations/5_TrumpVisitUnitedKingdom\\5_M.json\n",
      "Executing code for  test_parsing_no_annotations/5_TrumpVisitUnitedKingdom\\5_R.json\n",
      "Executing code for  test_parsing_no_annotations/5_TrumpVisitUnitedKingdom\\5_RR.json\n",
      "Reading in files from folder: 6_Asylum-SeekingMigrantCaravan\n",
      "Executing code for  test_parsing_no_annotations/6_Asylum-SeekingMigrantCaravan\\6_L.json\n",
      "Executing code for  test_parsing_no_annotations/6_Asylum-SeekingMigrantCaravan\\6_LL.json\n",
      "Executing code for  test_parsing_no_annotations/6_Asylum-SeekingMigrantCaravan\\6_M.json\n",
      "Executing code for  test_parsing_no_annotations/6_Asylum-SeekingMigrantCaravan\\6_R.json\n",
      "Executing code for  test_parsing_no_annotations/6_Asylum-SeekingMigrantCaravan\\6_RR.json\n",
      "Reading in files from folder: 7_TrumpDelaysTariff\n",
      "Executing code for  test_parsing_no_annotations/7_TrumpDelaysTariff\\7_L.json\n",
      "Executing code for  test_parsing_no_annotations/7_TrumpDelaysTariff\\7_LL.json\n",
      "Executing code for  test_parsing_no_annotations/7_TrumpDelaysTariff\\7_M.json\n",
      "Executing code for  test_parsing_no_annotations/7_TrumpDelaysTariff\\7_R.json\n",
      "Executing code for  test_parsing_no_annotations/7_TrumpDelaysTariff\\7_RR.json\n",
      "Reading in files from folder: 8_MuellerQuestionsTrump\n",
      "Executing code for  test_parsing_no_annotations/8_MuellerQuestionsTrump\\8_L.json\n",
      "Executing code for  test_parsing_no_annotations/8_MuellerQuestionsTrump\\8_LL.json\n",
      "Executing code for  test_parsing_no_annotations/8_MuellerQuestionsTrump\\8_M.json\n",
      "Executing code for  test_parsing_no_annotations/8_MuellerQuestionsTrump\\8_R.json\n",
      "Executing code for  test_parsing_no_annotations/8_MuellerQuestionsTrump\\8_RR.json\n",
      "Reading in files from folder: 9_Iranfiles\n",
      "Executing code for  test_parsing_no_annotations/9_Iranfiles\\9_L.json\n",
      "Executing code for  test_parsing_no_annotations/9_Iranfiles\\9_LL.json\n",
      "Executing code for  test_parsing_no_annotations/9_Iranfiles\\9_M.json\n",
      "Executing code for  test_parsing_no_annotations/9_Iranfiles\\9_R.json\n",
      "Executing code for  test_parsing_no_annotations/9_Iranfiles\\9_RR.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = 'test_parsing_no_annotations'    # the path of the folder \n",
    "\n",
    "df = pd.DataFrame(columns=[\"authors\", \"date_download\", \"date_modify\", \"date_publish\", \"description\", \"filename\", \"image_url\", \"language\", \"localpath\", \"source_domain\", \"text\", \"title\", \"title_page\", \"title_rss\", \"url\"])\n",
    "\n",
    "for filename in os.listdir(path)[1:]:\n",
    "    frames = []\n",
    "    print(\"Reading in files from folder: \" + filename)\n",
    "    for full_filename in glob.glob(os.path.join(path+\"/\"+filename, \"*.json\")):    #iterate through every file\n",
    "        print(\"Executing code for \", str(full_filename))\n",
    "        with open(full_filename, encoding='utf-8', mode='r') as currentFile:\n",
    "            jo = json.loads(currentFile.read())\n",
    "            df_tmp = pd.DataFrame({\"authors\": [jo[\"authors\"]], \"date_download\": jo[\"date_download\"], \"date_modify\": jo[\"date_modify\"], \"date_publish\": jo[\"date_publish\"], \"description\": jo[\"description\"], \"filename\": filename, \"image_url\": jo[\"image_url\"], \"language\": jo[\"language\"], \"localpath\": jo[\"localpath\"], \"source_domain\": jo[\"source_domain\"], \"text\": jo[\"text\"], \"title\": jo[\"title\"], \"title_page\": jo[\"title_page\"], \"title_rss\": jo[\"title_rss\"], \"url\": jo[\"url\"]})\n",
    "            df = pd.concat([df, df_tmp], ignore_index=True, axis = 0)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>date_download</th>\n",
       "      <th>date_modify</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>description</th>\n",
       "      <th>filename</th>\n",
       "      <th>image_url</th>\n",
       "      <th>language</th>\n",
       "      <th>localpath</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>title_page</th>\n",
       "      <th>title_rss</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_L</td>\n",
       "      <td>WEST PALM BEACH, Fla. — President Trump dispat...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Donald Trump is planning to meet with the Nort...</td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_LL</td>\n",
       "      <td>Central Intelligence Agency Director Mike Pomp...</td>\n",
       "      <td>CIA Director Mike Pompeo secretly met with Nor...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>President Donald Trump says conversations betw...</td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_M</td>\n",
       "      <td>PALM BEACH, Fla. — President Trump began meeti...</td>\n",
       "      <td>Mike Pompeo, Trump's secretary of State pick, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_R</td>\n",
       "      <td>The Washington Post reports the CIA director m...</td>\n",
       "      <td>Report: Mike Pompeo met with Kim Jong Un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_RR</td>\n",
       "      <td>CIA Director Mike Pompeo, now President Donald...</td>\n",
       "      <td>Report: Mike Pompeo secretly met with Kim Jong...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authors date_download date_modify date_publish  \\\n",
       "0      []          None        None         None   \n",
       "1      []          None        None         None   \n",
       "2      []          None        None         None   \n",
       "3      []          None        None         None   \n",
       "4      []          None        None         None   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1  Donald Trump is planning to meet with the Nort...   \n",
       "2  President Donald Trump says conversations betw...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                   filename image_url language localpath  \\\n",
       "0  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "1  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "2  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "3  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "4  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "\n",
       "  source_domain                                               text  \\\n",
       "0           0_L  WEST PALM BEACH, Fla. — President Trump dispat...   \n",
       "1          0_LL  Central Intelligence Agency Director Mike Pomp...   \n",
       "2           0_M  PALM BEACH, Fla. — President Trump began meeti...   \n",
       "3           0_R  The Washington Post reports the CIA director m...   \n",
       "4          0_RR  CIA Director Mike Pompeo, now President Donald...   \n",
       "\n",
       "                                               title title_page title_rss  \\\n",
       "0                                                          None      None   \n",
       "1  CIA Director Mike Pompeo secretly met with Nor...       None      None   \n",
       "2  Mike Pompeo, Trump's secretary of State pick, ...       None      None   \n",
       "3           Report: Mike Pompeo met with Kim Jong Un       None      None   \n",
       "4  Report: Mike Pompeo secretly met with Kim Jong...       None      None   \n",
       "\n",
       "    url  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "docs = []\n",
    "\n",
    "for element in tqdm(df[\"text\"]):\n",
    "    doc = nlp(element)\n",
    "    docs.append(doc)\n",
    "\n",
    "df[\"doc\"] = docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displacy.render(list(docs[0].sents)[1:2])   #display the first sentence of the first article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>date_download</th>\n",
       "      <th>date_modify</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>description</th>\n",
       "      <th>filename</th>\n",
       "      <th>image_url</th>\n",
       "      <th>language</th>\n",
       "      <th>localpath</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>title_page</th>\n",
       "      <th>title_rss</th>\n",
       "      <th>url</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_L</td>\n",
       "      <td>WEST PALM BEACH, Fla. — President Trump dispat...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Donald Trump is planning to meet with the Nort...</td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_LL</td>\n",
       "      <td>Central Intelligence Agency Director Mike Pomp...</td>\n",
       "      <td>CIA Director Mike Pompeo secretly met with Nor...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(Central, Intelligence, Agency, Director, Mike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>President Donald Trump says conversations betw...</td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_M</td>\n",
       "      <td>PALM BEACH, Fla. — President Trump began meeti...</td>\n",
       "      <td>Mike Pompeo, Trump's secretary of State pick, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(PALM, BEACH, ,, Fla., —, President, Trump, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_R</td>\n",
       "      <td>The Washington Post reports the CIA director m...</td>\n",
       "      <td>Report: Mike Pompeo met with Kim Jong Un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(The, Washington, Post, reports, the, CIA, dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0_CIADirectorMikePompeoMeetingNorthKorea</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>0_RR</td>\n",
       "      <td>CIA Director Mike Pompeo, now President Donald...</td>\n",
       "      <td>Report: Mike Pompeo secretly met with Kim Jong...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(CIA, Director, Mike, Pompeo, ,, now, Presiden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authors date_download date_modify date_publish  \\\n",
       "0      []          None        None         None   \n",
       "1      []          None        None         None   \n",
       "2      []          None        None         None   \n",
       "3      []          None        None         None   \n",
       "4      []          None        None         None   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1  Donald Trump is planning to meet with the Nort...   \n",
       "2  President Donald Trump says conversations betw...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                   filename image_url language localpath  \\\n",
       "0  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "1  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "2  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "3  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "4  0_CIADirectorMikePompeoMeetingNorthKorea      None       en      None   \n",
       "\n",
       "  source_domain                                               text  \\\n",
       "0           0_L  WEST PALM BEACH, Fla. — President Trump dispat...   \n",
       "1          0_LL  Central Intelligence Agency Director Mike Pomp...   \n",
       "2           0_M  PALM BEACH, Fla. — President Trump began meeti...   \n",
       "3           0_R  The Washington Post reports the CIA director m...   \n",
       "4          0_RR  CIA Director Mike Pompeo, now President Donald...   \n",
       "\n",
       "                                               title title_page title_rss  \\\n",
       "0                                                          None      None   \n",
       "1  CIA Director Mike Pompeo secretly met with Nor...       None      None   \n",
       "2  Mike Pompeo, Trump's secretary of State pick, ...       None      None   \n",
       "3           Report: Mike Pompeo met with Kim Jong Un       None      None   \n",
       "4  Report: Mike Pompeo secretly met with Kim Jong...       None      None   \n",
       "\n",
       "    url                                                doc  \n",
       "0  None  (WEST, PALM, BEACH, ,, Fla., —, President, Tru...  \n",
       "1  None  (Central, Intelligence, Agency, Director, Mike...  \n",
       "2  None  (PALM, BEACH, ,, Fla., —, President, Trump, be...  \n",
       "3  None  (The, Washington, Post, reports, the, CIA, dir...  \n",
       "4  None  (CIA, Director, Mike, Pompeo, ,, now, Presiden...  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if the token ids are concurrent within the sentence, i.e. 3-4-5-6, not 3-4-6-7\n",
    "def checkContinuous(nums):\n",
    "   if len(nums) < 1:\n",
    "      return False\n",
    "   min_val = min(nums)\n",
    "   max_val = max(nums)\n",
    "   if max_val - min_val + 1 == len(nums):\n",
    "      for i in range(len(nums)):\n",
    "         if nums[i] < 0:\n",
    "            j = -nums[i] - min_val\n",
    "         else:\n",
    "            j = nums[i] - min_val\n",
    "            if nums[j] > 0:\n",
    "               nums[j] = -nums[j]\n",
    "            else:\n",
    "               return False\n",
    "      return True\n",
    "   return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if a token has children it refers to\n",
    "def checkSingleton(doc, fitting_tokens_docID):\n",
    "    counter = 0\n",
    "    tokens = []\n",
    "    for t in fitting_tokens_docID:\n",
    "        tokens.append(doc[t])\n",
    "\n",
    "    for t in fitting_tokens_docID:\n",
    "        token = doc[t]\n",
    "        for c in token.children:\n",
    "            if not c in tokens:\n",
    "                counter = counter + 1\n",
    "\n",
    "    if counter == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing code for  2019_annot\\0_CIADirectorMikePompeoMeetingNorthKorea.csv\n",
      "Executing code for  2019_annot\\1_ComeyMemo.csv\n",
      "Executing code for  2019_annot\\2_NorthKoreaNuclearStopAnnouncement.csv\n",
      "Executing code for  2019_annot\\3_DemocratsSueRUTrump.csv\n",
      "Executing code for  2019_annot\\4_TrumpDealIran.csv\n",
      "Executing code for  2019_annot\\5_TrumpVisitUnitedKingdom.csv\n",
      "Executing code for  2019_annot\\6_Asylum-SeekingMigrantCaravan.csv\n",
      "Executing code for  2019_annot\\7_TrumpDelaysTariff.csv\n",
      "Executing code for  2019_annot\\8_MuellerQuestionsTrump.csv\n",
      "Executing code for  2019_annot\\9_Iranfiles.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Document name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Weight score</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Creation date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Document group</th>\n",
       "      <th>Area</th>\n",
       "      <th>Coverage %</th>\n",
       "      <th>Beginning</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>●</td>\n",
       "      <td>0_R</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0</td>\n",
       "      <td>Kim Jong Un</td>\n",
       "      <td>maxku</td>\n",
       "      <td>19-Apr-18 17:15:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>●</td>\n",
       "      <td>0_R</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>CIA director</td>\n",
       "      <td>maxku</td>\n",
       "      <td>19-Apr-18 17:18:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>●</td>\n",
       "      <td>0_R</td>\n",
       "      <td>PRK\\Jong Un</td>\n",
       "      <td>0</td>\n",
       "      <td>North Korean leader</td>\n",
       "      <td>maxku</td>\n",
       "      <td>19-Apr-18 17:18:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>●</td>\n",
       "      <td>0_R</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>chief White House correspondent</td>\n",
       "      <td>maxku</td>\n",
       "      <td>19-Apr-18 17:18:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>●</td>\n",
       "      <td>0_R</td>\n",
       "      <td>PRK\\Jong Un</td>\n",
       "      <td>0</td>\n",
       "      <td>North Korean dictator</td>\n",
       "      <td>maxku</td>\n",
       "      <td>19-Apr-18 17:19:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>0.56</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Color Document name         Code  Weight score  \\\n",
       "0     ●           0_R          PRK             0   \n",
       "1     ●           0_R          USA             0   \n",
       "2     ●           0_R  PRK\\Jong Un             0   \n",
       "3     ●           0_R          USA             0   \n",
       "4     ●           0_R  PRK\\Jong Un             0   \n",
       "\n",
       "                           Segment Author       Creation date Comment  \\\n",
       "0                      Kim Jong Un  maxku  19-Apr-18 17:15:58     NaN   \n",
       "1                     CIA director  maxku  19-Apr-18 17:18:30     NaN   \n",
       "2              North Korean leader  maxku  19-Apr-18 17:18:38     NaN   \n",
       "3  chief White House correspondent  maxku  19-Apr-18 17:18:48     NaN   \n",
       "4            North Korean dictator  maxku  19-Apr-18 17:19:18     NaN   \n",
       "\n",
       "   Document group  Area  Coverage %  Beginning  End  \n",
       "0             NaN    11        0.30          1    1  \n",
       "1             NaN    12        0.32          2    2  \n",
       "2             NaN    19        0.51          2    2  \n",
       "3             NaN    31        0.83          2    2  \n",
       "4             NaN    21        0.56          3    3  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read other csvs for annotations\n",
    "path_annotations = '2019_annot/'    # the path of the folder \n",
    "\n",
    "df_annotations = pd.DataFrame()\n",
    "\n",
    "for full_filename in glob.glob(os.path.join(path_annotations, \"*.csv\")):    #iterate through every file\n",
    "    print(\"Executing code for \", str(full_filename))\n",
    "    with open(full_filename, encoding='utf-8', mode='r') as currentFile:\n",
    "        df_tmp = pd.read_csv(currentFile)\n",
    "        df_annotations = pd.concat([df_annotations, df_tmp], ignore_index=True, axis = 0)\n",
    "    \n",
    "\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphs(document):\n",
    "    start = 0\n",
    "    for token in document:\n",
    "        if token.is_space and token.text.count(\"\\n\") > 1:\n",
    "            yield document[start:token.i]\n",
    "            start = token.i\n",
    "    yield document[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(doc, fitting_tokens_docID):\n",
    "    context_min_id = min(fitting_tokens_docID) - 250\n",
    "    context_max_id = max(fitting_tokens_docID) + 250\n",
    "    if context_min_id < 0:\n",
    "        context_min_id = 0\n",
    "    if context_max_id > len(doc):\n",
    "        context_max_id = len(doc)-1\n",
    "\n",
    "    mention_context = doc[context_min_id:context_max_id]\n",
    "    mention_context_str = []\n",
    "    for c in mention_context:\n",
    "        mention_context_str.append(c.text)\n",
    "    return mention_context_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 50 dataframe rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [04:04, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the segment does not match 100%: the meeting\n",
      "Sentence: Just days earlier, President Trump expressed a caution about the planned meeting with Kim, explaining he would \"leave the meeting\" if it's not \"fruitful.\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [06:21, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the segment does not match 100%: the agreement\n",
      "Sentence: He made no commitment, however, leaving it unclear whether he will pull out of the agreement by a May 12 deadline he has set to either \"fix\" the Iran agreement or walk away from it. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [15:52, 19.06s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_preparation_list = []\n",
    "tokens_amount = 0\n",
    "prev_doc = 0\n",
    "\n",
    "print(\"Going to process \" + str(len(df)) + \" dataframe rows...\")\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    doc = row[\"doc\"]\n",
    "    filename = row[\"filename\"]\n",
    "    description = row[\"description\"]\n",
    "    doc_id = row[\"source_domain\"].split(\"_\")[0]\n",
    "    pol_direction = row[\"source_domain\"].split(\"_\")[1]\n",
    "    doc_id_full = row[\"source_domain\"]\n",
    "    doc_unique_id = doc_id_full+\"_\"+str(i)\n",
    "\n",
    "    #count the amount of tokens for each reneral topic (only the max value in the dataframe represents the correct tokens_number at the end)\n",
    "    if prev_doc == doc_id:\n",
    "        prev_doc = doc_id\n",
    "        tokens_amount = tokens_amount + len(doc)\n",
    "    else:\n",
    "        tokens_amount = len(doc)\n",
    "        prev_doc = doc_id\n",
    "    \n",
    "    #compare whole segment with tokens\n",
    "    #iterate over tokens and segment tokens seperately\n",
    "    #if they are close enough (+-1 in position) accept it (maybe print warning)\n",
    "    #take the accepted token and determine the head\n",
    "    #token ids should match the exact appearences in the text of the segment tokens\n",
    "    #take care of abbreviations\n",
    "\n",
    "    for j, sentence in enumerate(doc.sents):\n",
    "        for anno_i, row_anno in df_annotations.iterrows():\n",
    "            if doc_id_full == row_anno[\"Document name\"]:\n",
    "                if row_anno[\"Segment\"] in sentence.text:\n",
    "\n",
    "                    fitting_tokens = []\n",
    "                    fitting_tokens_docID = []\n",
    "                    fitting_token_str = []\n",
    "                    seg_token = 0\n",
    "                    iterations_without_token_match = 0\n",
    "                \n",
    "                    segment_doc = nlp(row_anno[\"Segment\"])\n",
    "                    segment_tokenized = []\n",
    "\n",
    "                    for t in segment_doc:\n",
    "                        segment_tokenized.append(t)\n",
    "\n",
    "                    for token in sentence:\n",
    "\n",
    "                        if len(segment_tokenized) <= seg_token:\n",
    "                            #add to the list\n",
    "                            if seg_token >= 1:\n",
    "                                sent_id = j\n",
    "                                text = row[\"text\"]\n",
    "                                code = row_anno[\"Code\"].replace(\"\\\\\", \" \")\n",
    "                                segment = row_anno[\"Segment\"]\n",
    "                                score = -1  #not row_anno[\"Weight score\"], not that important (legacy)\n",
    "                                is_continuous = checkContinuous(tokens_number[:])\n",
    "                                is_singleton = checkSingleton(doc, fitting_tokens_docID)\n",
    "                                mention_id = doc_unique_id+\"_\"+str(sent_id)+\"_\"+str(tokens_number[0])\n",
    "                                head_id = token.head.i - sentence.start\n",
    "                                mention_head = token.head.text\n",
    "                                head_pos = token.head.pos_\n",
    "                                head_lemma = token.head.lemma_\n",
    "                                head_str = token.head.text\n",
    "                                coref_type = \"STRICT\"\n",
    "                                mention_context_str = get_context(doc, fitting_tokens_docID)\n",
    "                                \n",
    "                                #determine the spacy ner type\n",
    "                                mention_ner = \"\"\n",
    "                                for t in tokens:\n",
    "                                    if t.head.ent_type_ != \"\":\n",
    "                                        mention_ner = t.head.ent_type_\n",
    "                                if mention_ner == \"\":\n",
    "                                    mention_ner = \"O\"\n",
    "\n",
    "                                coref_chain = \"tbd\"\n",
    "                                mention_type = \"tbd\"\n",
    "                                \n",
    "                                if iterations_without_token_match >= 1:\n",
    "                                    print(\"Warning: the segment does not match 100%: \" + segment)\n",
    "                                    print(\"Sentence: \" + str(sentence))\n",
    "\n",
    "                                df_preparation_list.append([coref_chain, code, segment, tokens_amount, mention_ner, head_pos, head_lemma, mention_head, code, doc_unique_id, doc_id, pol_direction, is_continuous, is_singleton, text, sentence.text, mention_id, mention_type, mention_type, score, sent_id, mention_context_str, fitting_tokens, fitting_token_str, row_anno[\"Segment\"], filename.split(\"_\")[0], coref_type, code, head_str, head_id])\n",
    "                                #break   #only one mention of the same kind per sentence is valid\n",
    "\n",
    "                            fitting_tokens = []\n",
    "                            fitting_tokens_docID = []\n",
    "                            fitting_token_str = []\n",
    "                            seg_token = 0\n",
    "\n",
    "                        if token.text == segment_tokenized[seg_token].text:\n",
    "                            if seg_token == 0:\n",
    "                                iterations_without_token_match = 0\n",
    "                            seg_token = seg_token + 1\n",
    "                            fitting_tokens.append(token.i - sentence.start)     #the id of the token within a sentence\n",
    "                            fitting_tokens_docID.append(token.i)\n",
    "                            fitting_token_str.append(token.text)\n",
    "\n",
    "                            tokens = []\n",
    "                            tokens_str = \"\"\n",
    "                            tokens_number = []\n",
    "                            for t in token.head.subtree:\n",
    "                                tokens.append(t)\n",
    "                                tokens_str = tokens_str + \" \" + t.text\n",
    "                                tokens_number.append(t.i)\n",
    "                        else:\n",
    "                            iterations_without_token_match = iterations_without_token_match + 1\n",
    "                            if iterations_without_token_match > 1:\n",
    "                                #reset detection if the tokens are spread to far (not exact matching)\n",
    "                                tokens = []\n",
    "                                tokens_str = \"\"\n",
    "                                tokens_number = []\n",
    "                                fitting_tokens = []\n",
    "                                fitting_tokens_docID = []\n",
    "                                fitting_token_str = []\n",
    "                                iterations_without_token_match = 0\n",
    "                                seg_token = 0\n",
    "                \n",
    "\n",
    "        #these breaks are just for debugging (faster calc speed)\n",
    "        #if j>=15:\n",
    "            #break\n",
    "    #if i>=10:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_preparation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>segment</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>...</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>fitting_tokens</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>head_str</th>\n",
       "      <th>head_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[President, Trump]</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>said</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[C.I.A., director]</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>Mike Pompeo</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>[Mike, Pompeo]</td>\n",
       "      <td>Mike Pompeo</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[North, Korea]</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>meet</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[17, 18, 19, 20]</td>\n",
       "      <td>[Kim, Jong, -, un]</td>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>meet</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[16, 17]</td>\n",
       "      <td>[United, States]</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>said</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>Mr. Trump</td>\n",
       "      <td>1650</td>\n",
       "      <td>ORG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>allude</td>\n",
       "      <td>alluded</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[Mr., Trump]</td>\n",
       "      <td>Mr. Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>alluded</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>Mr. Trump</td>\n",
       "      <td>1650</td>\n",
       "      <td>ORG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>allude</td>\n",
       "      <td>alluded</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[Mr., Trump]</td>\n",
       "      <td>Mr. Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>alluded</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>a potential meeting of the two leaders</td>\n",
       "      <td>1650</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>allude</td>\n",
       "      <td>alluded</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[43, 44, 45, 46, 47, 48, 49]</td>\n",
       "      <td>[a, potential, meeting, of, the, two, leaders]</td>\n",
       "      <td>a potential meeting of the two leaders</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>alluded</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tbd</td>\n",
       "      <td>Properties Importance Important &amp; Intense</td>\n",
       "      <td>extremely high levels</td>\n",
       "      <td>1650</td>\n",
       "      <td>O</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be</td>\n",
       "      <td>was</td>\n",
       "      <td>Properties Importance Important &amp; Intense</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[27, 28, 29]</td>\n",
       "      <td>[extremely, high, levels]</td>\n",
       "      <td>extremely high levels</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Properties Importance Important &amp; Intense</td>\n",
       "      <td>was</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   coref_chain                                       code  \\\n",
       "0          tbd                                  USA Trump   \n",
       "1          tbd                                        USA   \n",
       "2          tbd                            USA Mike Pompeo   \n",
       "3          tbd                                        PRK   \n",
       "4          tbd                                PRK Jong Un   \n",
       "..         ...                                        ...   \n",
       "95         tbd                                        USA   \n",
       "96         tbd                                  USA Trump   \n",
       "97         tbd                                  USA Trump   \n",
       "98         tbd                             PRK USA Summit   \n",
       "99         tbd  Properties Importance Important & Intense   \n",
       "\n",
       "                                   segment  tokens_amount mention_ner  \\\n",
       "0                          President Trump           1650      PERSON   \n",
       "1                          C.I.A. director           1650      PERSON   \n",
       "2                              Mike Pompeo           1650      PERSON   \n",
       "3                              North Korea           1650         GPE   \n",
       "4                              Kim Jong-un           1650      PERSON   \n",
       "..                                     ...            ...         ...   \n",
       "95                           United States           1650         GPE   \n",
       "96                               Mr. Trump           1650         ORG   \n",
       "97                               Mr. Trump           1650         ORG   \n",
       "98  a potential meeting of the two leaders           1650           O   \n",
       "99                   extremely high levels           1650           O   \n",
       "\n",
       "   mention_head_pos mention_head_lemma mention_head  \\\n",
       "0              VERB                say         said   \n",
       "1             PROPN             Pompeo       Pompeo   \n",
       "2              VERB           dispatch   dispatched   \n",
       "3              VERB               meet         meet   \n",
       "4              VERB               meet         meet   \n",
       "..              ...                ...          ...   \n",
       "95             VERB                say         said   \n",
       "96             VERB             allude      alluded   \n",
       "97             VERB             allude      alluded   \n",
       "98             VERB             allude      alluded   \n",
       "99              AUX                 be          was   \n",
       "\n",
       "                                   coref_link doc_id_full  ... sent_id  \\\n",
       "0                                   USA Trump       0_L_0  ...       1   \n",
       "1                                         USA       0_L_0  ...       1   \n",
       "2                             USA Mike Pompeo       0_L_0  ...       1   \n",
       "3                                         PRK       0_L_0  ...       1   \n",
       "4                                 PRK Jong Un       0_L_0  ...       1   \n",
       "..                                        ...         ...  ...     ...   \n",
       "95                                        USA       0_L_0  ...       2   \n",
       "96                                  USA Trump       0_L_0  ...       2   \n",
       "97                                  USA Trump       0_L_0  ...       2   \n",
       "98                             PRK USA Summit       0_L_0  ...       2   \n",
       "99  Properties Importance Important & Intense       0_L_0  ...       2   \n",
       "\n",
       "                                      mention_context  \\\n",
       "0   [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "1   [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "2   [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "3   [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "4   [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "..                                                ...   \n",
       "95  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "96  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "97  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "98  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "99  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "\n",
       "                   tokens_number  \\\n",
       "0                         [0, 1]   \n",
       "1                         [4, 5]   \n",
       "2                         [6, 7]   \n",
       "3                        [9, 10]   \n",
       "4               [17, 18, 19, 20]   \n",
       "..                           ...   \n",
       "95                      [16, 17]   \n",
       "96                        [0, 1]   \n",
       "97                        [0, 1]   \n",
       "98  [43, 44, 45, 46, 47, 48, 49]   \n",
       "99                  [27, 28, 29]   \n",
       "\n",
       "                                    fitting_tokens  \\\n",
       "0                               [President, Trump]   \n",
       "1                               [C.I.A., director]   \n",
       "2                                   [Mike, Pompeo]   \n",
       "3                                   [North, Korea]   \n",
       "4                               [Kim, Jong, -, un]   \n",
       "..                                             ...   \n",
       "95                                [United, States]   \n",
       "96                                    [Mr., Trump]   \n",
       "97                                    [Mr., Trump]   \n",
       "98  [a, potential, meeting, of, the, two, leaders]   \n",
       "99                       [extremely, high, levels]   \n",
       "\n",
       "                                tokens_str topic_id coref_type  \\\n",
       "0                          President Trump        0     STRICT   \n",
       "1                          C.I.A. director        0     STRICT   \n",
       "2                              Mike Pompeo        0     STRICT   \n",
       "3                              North Korea        0     STRICT   \n",
       "4                              Kim Jong-un        0     STRICT   \n",
       "..                                     ...      ...        ...   \n",
       "95                           United States        0     STRICT   \n",
       "96                               Mr. Trump        0     STRICT   \n",
       "97                               Mr. Trump        0     STRICT   \n",
       "98  a potential meeting of the two leaders        0     STRICT   \n",
       "99                   extremely high levels        0     STRICT   \n",
       "\n",
       "                                  description    head_str  head_id  \n",
       "0                                   USA Trump        said       47  \n",
       "1                                         USA      Pompeo        7  \n",
       "2                             USA Mike Pompeo  dispatched        2  \n",
       "3                                         PRK        meet       12  \n",
       "4                                 PRK Jong Un        meet       12  \n",
       "..                                        ...         ...      ...  \n",
       "95                                        USA        said       10  \n",
       "96                                  USA Trump     alluded        2  \n",
       "97                                  USA Trump     alluded        2  \n",
       "98                             PRK USA Summit     alluded        2  \n",
       "99  Properties Importance Important & Intense         was       18  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_df = pd.DataFrame(df_preparation_list, columns=[\"coref_chain\", \"code\", \"segment\", \"tokens_amount\", \"mention_ner\", \"mention_head_pos\", \"mention_head_lemma\", \"mention_head\", \"coref_link\", \"doc_id_full\",\"doc_id\", \"pol_direction\", \"is_continuous\", \"is_singleton\", \"text\", \"sentence\", \"mention_id\", \"mention_type\", \"mention_full_type\", \"score\", \"sent_id\", \"mention_context\", \"tokens_number\", \"fitting_tokens\", \"tokens_str\", \"topic_id\", \"coref_type\", \"description\", \"head_str\", \"head_id\"])\n",
    "mentions_df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the parmeters for lexical diversity\n",
    "#Diversity: Average number of unique head lemmas within a cluster\n",
    "#(excluding singletons for fair comparison)\n",
    "\n",
    "mentions_df = mentions_df.join(mentions_df.groupby(['topic_id', 'segment'])[\"mention_head_lemma\"].nunique(), on=['topic_id', 'segment'], rsuffix='_uniques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows from dataframe with duplicate code possibilities (just take the first one)\n",
    "mentions_df = mentions_df.drop_duplicates(subset=['segment', 'doc_id_full', 'sent_id', 'tokens_str'], keep='first')\n",
    "#print(len(mentions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 8838 mentions to calculate the PD (lexical diversity).\n",
      "pd_c: 0.0\n",
      "pd_c: 85.16071147798743\n",
      "pd_c: 37.1609756097561\n",
      "pd_c: 70.8652357494722\n",
      "pd_c: 48.106496178718395\n",
      "pd_c: 23.47826086956522\n",
      "62.83309641845406\n",
      "pd_c: 107.43254013067677\n",
      "pd_c: 39.027272727272724\n",
      "pd_c: 85.8485420599958\n",
      "pd_c: 48.89344879518073\n",
      "pd_c: 24.31578947368421\n",
      "77.97273829682153\n",
      "pd_c: 92.79622981581156\n",
      "pd_c: 56.107638888888886\n",
      "pd_c: 45.551020408163275\n",
      "pd_c: 58.28316712189546\n",
      "pd_c: 41.333333333333336\n",
      "66.95044432207506\n",
      "pd_c: 116.00242212465895\n",
      "pd_c: 90.96874999999999\n",
      "pd_c: 117.05915048704453\n",
      "pd_c: 91.45006366182837\n",
      "pd_c: 69.2952380952381\n",
      "102.61477827534823\n",
      "pd_c: 93.19831026637596\n",
      "pd_c: 115.99611154565788\n",
      "pd_c: 66.32901729418123\n",
      "pd_c: 71.12051907719609\n",
      "pd_c: 31.026204564666102\n",
      "87.1599827013236\n",
      "pd_c: 70.81065323565323\n",
      "pd_c: 78.7778681184012\n",
      "pd_c: 42.51136363636363\n",
      "pd_c: 36.16549019607843\n",
      "pd_c: 40.50515463917526\n",
      "60.829035091005196\n",
      "pd_c: 121.92105294476427\n",
      "pd_c: 108.23416860916862\n",
      "pd_c: 79.43911647407711\n",
      "pd_c: 64.50132275132275\n",
      "pd_c: 37.51282051282051\n",
      "93.47374237195977\n",
      "pd_c: 92.81729220859656\n",
      "pd_c: 53.50438710603089\n",
      "pd_c: 32.058140589569156\n",
      "pd_c: 87.30891131091133\n",
      "pd_c: 23.82075471698113\n",
      "69.1611608775084\n",
      "pd_c: 109.04871381253494\n",
      "pd_c: 48.5015406162465\n",
      "pd_c: 53.79409090909091\n",
      "pd_c: 91.786056124945\n",
      "pd_c: 46.748000000000005\n",
      "84.50464737883568\n",
      "pd_c: 95.4895238095238\n",
      "pd_c: 54.92886178861788\n",
      "pd_c: 44.532234617985125\n",
      "pd_c: 39.90996168582376\n",
      "[62.83309641845406, 77.97273829682153, 66.95044432207506, 102.61477827534823, 87.1599827013236, 60.829035091005196, 93.47374237195977, 69.1611608775084, 84.50464737883568]\n"
     ]
    }
   ],
   "source": [
    "#Also calculate the PD as in https://arxiv.org/pdf/2109.05250.pdf\n",
    "\n",
    "current_topic = \"0\"\n",
    "current_pol_dir = str(mentions_df.head(1)[\"pol_direction\"])\n",
    "current_doc = 0\n",
    "pd_c_list = []\n",
    "pd_total_list = []\n",
    "m_c = 0\n",
    "m_c_list = []\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sum_pd1 = 0\n",
    "sum_pd2 = 0\n",
    "\n",
    "\n",
    "print(\"Going to process \" + str(len(mentions_df)) + \" mentions to calculate the PD (lexical diversity).\")\n",
    "\n",
    "for i, row in mentions_df.iterrows():\n",
    "    m_c = m_c + 1\n",
    "                \n",
    "    if (current_doc != int(row[\"doc_id\"])) or (current_topic != str(row[\"doc_id\"])) or (current_pol_dir != str(row[\"pol_direction\"]) or (i == len(mentions_df)-1)):\n",
    "        unique_heads = list(set(mentions_df[(mentions_df.topic_id == current_topic) & (mentions_df.doc_id == str(current_doc)) & (mentions_df.pol_direction == str(current_pol_dir)) ][\"mention_head_lemma\"]))\n",
    "        reduced_df = mentions_df[(mentions_df.topic_id == current_topic) & (mentions_df.doc_id == str(current_doc)) & (mentions_df.pol_direction == str(current_pol_dir))]\n",
    "        reduced_df = reduced_df.reset_index()\n",
    "        #print(len(reduced_df))\n",
    "        #print(\"Found \" + str(len(unique_heads)) + \" unique heads.\")\n",
    "\n",
    "        for head in unique_heads:\n",
    "            u_h = 0\n",
    "            a_h = 0\n",
    "            phrases = []\n",
    "\n",
    "            for j, row2 in reduced_df.iterrows():\n",
    "                if len(reduced_df) != j+1:\n",
    "                    if row2[\"mention_head_lemma\"] == head: \n",
    "                        if row2[\"tokens_str\"] in phrases:\n",
    "                            a_h = a_h + 1\n",
    "                        else:\n",
    "                            phrases.append(row2[\"tokens_str\"])\n",
    "                            a_h = a_h + 1\n",
    "                            u_h = u_h + 1\n",
    "            \n",
    "                else:\n",
    "                    #calculate the sums within the division\n",
    "                    #if a_h == 0:\n",
    "                        #print(\"a_h is zero - probably error\")\n",
    "                        #print(u_h)\n",
    "                        #print(sum1)\n",
    "                        #print(sum2)\n",
    "                        #print(j)\n",
    "                    if a_h != 0:    \n",
    "                        sum1 = sum1 + (u_h / a_h)\n",
    "                        sum2 = sum2 + u_h\n",
    "                    #print(sum1)\n",
    "                    #print(sum2)\n",
    "    \n",
    "\n",
    "        #print(\"sum : \" + str(sum1) + \"  \" +  str(sum2))\n",
    "        #print(\"m_c : \" + str(m_c))\n",
    "\n",
    "        #conclude the division (PD_c)  \n",
    "        pd_c = (sum1 * sum2) / m_c\n",
    "        pd_c_list.append(pd_c)\n",
    "        m_c_list.append(m_c)\n",
    "\n",
    "        print(\"pd_c: \" + str(pd_c))\n",
    "        #calculate sums for the total PD\n",
    "        sum_pd1 = sum_pd1 + m_c * pd_c\n",
    "        sum_pd2 = sum_pd2 + m_c\n",
    "        \n",
    "        if (current_topic != row[\"topic_id\"]) or (i == len(mentions_df)-1):\n",
    "            pd_total = sum_pd1 / sum_pd2   \n",
    "            #print(pd_c_list)\n",
    "            print(pd_total)\n",
    "            pd_total_list.append(pd_total)\n",
    "            sum_pd1 = 0\n",
    "            sum_pd2 = 0\n",
    "\n",
    "        m_c = 0\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        m_c_list = []\n",
    "        pd_c_list = []\n",
    "\n",
    "    current_topic = str(row[\"topic_id\"])\n",
    "    current_doc = int(row[\"doc_id\"])\n",
    "    current_pol_dir = str(row[\"pol_direction\"])\n",
    "\n",
    "print(pd_total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>segment</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>fitting_tokens</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>head_str</th>\n",
       "      <th>head_id</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[President, Trump]</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Trump</td>\n",
       "      <td>said</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[C.I.A., director]</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>Mike Pompeo</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>[Mike, Pompeo]</td>\n",
       "      <td>Mike Pompeo</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA Mike Pompeo</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>[North, Korea]</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>meet</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[17, 18, 19, 20]</td>\n",
       "      <td>[Kim, Jong, -, un]</td>\n",
       "      <td>Kim Jong-un</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK Jong Un</td>\n",
       "      <td>meet</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  coref_chain             code          segment  tokens_amount mention_ner  \\\n",
       "0         tbd        USA Trump  President Trump           1650      PERSON   \n",
       "1         tbd              USA  C.I.A. director           1650      PERSON   \n",
       "2         tbd  USA Mike Pompeo      Mike Pompeo           1650      PERSON   \n",
       "3         tbd              PRK      North Korea           1650         GPE   \n",
       "4         tbd      PRK Jong Un      Kim Jong-un           1650      PERSON   \n",
       "\n",
       "  mention_head_pos mention_head_lemma mention_head       coref_link  \\\n",
       "0             VERB                say         said        USA Trump   \n",
       "1            PROPN             Pompeo       Pompeo              USA   \n",
       "2             VERB           dispatch   dispatched  USA Mike Pompeo   \n",
       "3             VERB               meet         meet              PRK   \n",
       "4             VERB               meet         meet      PRK Jong Un   \n",
       "\n",
       "  doc_id_full  ...                                    mention_context  \\\n",
       "0       0_L_0  ...  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "1       0_L_0  ...  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "2       0_L_0  ...  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "3       0_L_0  ...  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "4       0_L_0  ...  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "\n",
       "      tokens_number      fitting_tokens       tokens_str topic_id coref_type  \\\n",
       "0            [0, 1]  [President, Trump]  President Trump        0     STRICT   \n",
       "1            [4, 5]  [C.I.A., director]  C.I.A. director        0     STRICT   \n",
       "2            [6, 7]      [Mike, Pompeo]      Mike Pompeo        0     STRICT   \n",
       "3           [9, 10]      [North, Korea]      North Korea        0     STRICT   \n",
       "4  [17, 18, 19, 20]  [Kim, Jong, -, un]      Kim Jong-un        0     STRICT   \n",
       "\n",
       "       description    head_str head_id  mention_head_lemma_uniques  \n",
       "0        USA Trump        said      47                           4  \n",
       "1              USA      Pompeo       7                           1  \n",
       "2  USA Mike Pompeo  dispatched       2                           5  \n",
       "3              PRK        meet      12                          31  \n",
       "4      PRK Jong Un        meet      12                           2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "full_filename = 'aggr_m_conceptcategorization.csv'    # the path of the folder \n",
    "\n",
    "concept_df = pd.DataFrame(columns=[\"Color\", \"Document name\", \"Code\", \"Weight score\", \"Segment\", \"Author\", \"Creation date\", \"Comment\", \"Document group\", \"Area\", \"Coverage %\", \"Beginning\", \"End\"])\n",
    "\n",
    "with open(full_filename, encoding='utf-8', mode='r') as currentFile:\n",
    "    concept_df = pd.read_csv(currentFile)\n",
    "    \n",
    "print(len(concept_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>Code</th>\n",
       "      <th>type</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USA\\Trump</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>PRK</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>JPN\\Abe</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id            Code     type comments\n",
       "0         0       USA\\Trump    ACTOR      NaN\n",
       "1         0             USA  COUNTRY      NaN\n",
       "2         0             PRK  COUNTRY      NaN\n",
       "3         0  PRK USA Summit    EVENT      NaN\n",
       "4         0         JPN\\Abe    ACTOR      NaN"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8838\n",
      "3820\n"
     ]
    }
   ],
   "source": [
    "mentions_df.code = mentions_df.code.astype(str)\n",
    "mentions_df.doc_id = mentions_df.doc_id.astype(int)\n",
    "concept_df.topic_id = concept_df.topic_id.astype(int)\n",
    "concept_df.Code = concept_df.Code.astype(str)\n",
    "df_final = pd.merge(mentions_df, concept_df, how = \"left\", left_on = [\"doc_id\", \"code\"], right_on = [\"topic_id\", \"Code\"])\n",
    "print(len(df_final))\n",
    "\n",
    "#clean the data, some codes are null / do not have a type\n",
    "df_final = df_final.drop(\"comments\", axis = 1)\n",
    "df_final = df_final.dropna(axis=0)\n",
    "print(len(df_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>segment</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>...</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id_x</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>head_str</th>\n",
       "      <th>head_id</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "      <th>topic_id_y</th>\n",
       "      <th>Code</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>meet</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PRK</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tbd</td>\n",
       "      <td>USA</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tbd</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>meeting</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>EVENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tbd</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>...</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>leader</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>ACTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  coref_chain            code                  segment  tokens_amount  \\\n",
       "1         tbd             USA          C.I.A. director           1650   \n",
       "3         tbd             PRK              North Korea           1650   \n",
       "7         tbd             USA                   C.I.A.           1650   \n",
       "8         tbd  PRK USA Summit           summit meeting           1650   \n",
       "9         tbd     Trip to PRK  to meet with its leader           1650   \n",
       "\n",
       "  mention_ner mention_head_pos mention_head_lemma mention_head  \\\n",
       "1      PERSON            PROPN             Pompeo       Pompeo   \n",
       "3         GPE             VERB               meet         meet   \n",
       "7      PERSON             VERB           dispatch   dispatched   \n",
       "8      PERSON             NOUN            meeting      meeting   \n",
       "9      PERSON             NOUN             leader       leader   \n",
       "\n",
       "       coref_link doc_id_full  ...               tokens_str topic_id_x  \\\n",
       "1             USA       0_L_0  ...          C.I.A. director          0   \n",
       "3             PRK       0_L_0  ...              North Korea          0   \n",
       "7             USA       0_L_0  ...                   C.I.A.          0   \n",
       "8  PRK USA Summit       0_L_0  ...           summit meeting          0   \n",
       "9     Trip to PRK       0_L_0  ...  to meet with its leader          0   \n",
       "\n",
       "   coref_type     description    head_str head_id mention_head_lemma_uniques  \\\n",
       "1      STRICT             USA      Pompeo       7                          1   \n",
       "3      STRICT             PRK        meet      12                         31   \n",
       "7      STRICT             USA  dispatched       2                          2   \n",
       "8      STRICT  PRK USA Summit     meeting      32                          1   \n",
       "9      STRICT     Trip to PRK      leader      15                          1   \n",
       "\n",
       "  topic_id_y            Code     type  \n",
       "1        0.0             USA  COUNTRY  \n",
       "3        0.0             PRK  COUNTRY  \n",
       "7        0.0             USA  COUNTRY  \n",
       "8        0.0  PRK USA Summit    EVENT  \n",
       "9        0.0     Trip to PRK   ACTION  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_id = 1\n",
    "\n",
    "for i, row in df_final.iterrows():\n",
    "    mention_full_type = row[\"type\"]\n",
    "    mention_type = mention_full_type.replace(\"-\",\"\")\n",
    "    coref_id = coref_id + 1\n",
    "    coref_chain = mention_type + \"_\" + str(shortuuid.random(8))\n",
    "    df_final.at[i, \"coref_chain\"] = coref_chain\n",
    "    df_final.at[i, \"mention_type\"] = mention_type\n",
    "    df_final.at[i, \"mention_full_type\"] = mention_full_type\n",
    "\n",
    "df_final.rename(columns={\"topic_id_x\": \"topic_id\"}, inplace = True)\n",
    "#drop unwanted columns for the output\n",
    "df_final = df_final.drop([\"segment\", \"Code\", \"text\", \"sentence\", \"fitting_tokens\", \"topic_id_y\", \"type\", \"head_id\", \"head_str\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.reset_index(drop=True,inplace=True)\n",
    "\n",
    "with open(f'./mentions_df.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(ujson.dumps(df_final.to_dict('index'), indent=4, ensure_ascii=False, escape_forward_slashes=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_full_type</th>\n",
       "      <th>score</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNTRY_ZVbotWQj</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COUNTRY_fjep4p8J</td>\n",
       "      <td>PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COUNTRY_AQa6Civp</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVENT_Am92KUuK</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[31, 32]</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTION_pgyA4XU5</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        coref_chain            code  tokens_amount mention_ner  \\\n",
       "0  COUNTRY_ZVbotWQj             USA           1650      PERSON   \n",
       "1  COUNTRY_fjep4p8J             PRK           1650         GPE   \n",
       "2  COUNTRY_AQa6Civp             USA           1650      PERSON   \n",
       "3    EVENT_Am92KUuK  PRK USA Summit           1650      PERSON   \n",
       "4   ACTION_pgyA4XU5     Trip to PRK           1650      PERSON   \n",
       "\n",
       "  mention_head_pos mention_head_lemma mention_head      coref_link  \\\n",
       "0            PROPN             Pompeo       Pompeo             USA   \n",
       "1             VERB               meet         meet             PRK   \n",
       "2             VERB           dispatch   dispatched             USA   \n",
       "3             NOUN            meeting      meeting  PRK USA Summit   \n",
       "4             NOUN             leader       leader     Trip to PRK   \n",
       "\n",
       "  doc_id_full  doc_id  ... mention_full_type  score  sent_id  \\\n",
       "0       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "1       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "2       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "3       0_L_0       0  ...             EVENT     -1        1   \n",
       "4       0_L_0       0  ...            ACTION     -1        1   \n",
       "\n",
       "                                     mention_context         tokens_number  \\\n",
       "0  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...                [4, 5]   \n",
       "1  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...               [9, 10]   \n",
       "2  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...                   [4]   \n",
       "3  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...              [31, 32]   \n",
       "4  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...  [11, 12, 13, 14, 15]   \n",
       "\n",
       "                tokens_str  topic_id  coref_type     description  \\\n",
       "0          C.I.A. director         0      STRICT             USA   \n",
       "1              North Korea         0      STRICT             PRK   \n",
       "2                   C.I.A.         0      STRICT             USA   \n",
       "3           summit meeting         0      STRICT  PRK USA Summit   \n",
       "4  to meet with its leader         0      STRICT     Trip to PRK   \n",
       "\n",
       "  mention_head_lemma_uniques  \n",
       "0                          1  \n",
       "1                         31  \n",
       "2                          2  \n",
       "3                          1  \n",
       "4                          1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define entities and event mentions to generate two different json files later\n",
    "events = [\"ACTION\", \"EVENT\", \"MISC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>pol_direction</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_full_type</th>\n",
       "      <th>score</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVENT_Am92KUuK</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[31, 32]</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTION_pgyA4XU5</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACTION_6dhrjKQJ</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[25, 26, 27, 28, 29, 30, 31, 32]</td>\n",
       "      <td>to lay the groundwork for a summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EVENT_LH6yuqwW</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>O</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[44, 45]</td>\n",
       "      <td>potential meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EVENT_8Lu6Sue9</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>allude</td>\n",
       "      <td>alluded</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[43, 44, 45, 46, 47, 48, 49]</td>\n",
       "      <td>a potential meeting of the two leaders</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>MISC_p7QxVGw6</td>\n",
       "      <td>IRN nuclear activity</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>IRN nuclear activity</td>\n",
       "      <td>9_RR_49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[U.S., intelligence, reportedly, confirmed, th...</td>\n",
       "      <td>[13, 14, 15, 16]</td>\n",
       "      <td>a nuclear weapons program</td>\n",
       "      <td>9</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>IRN nuclear activity</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>EVENT_YhnKwFRg</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>come</td>\n",
       "      <td>came</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>9_RR_49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[U.S., intelligence, reportedly, confirmed, th...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>Netanyahu's presentation</td>\n",
       "      <td>9</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>MISC_AwtnKuR6</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>9_RR_49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[Israeli, Prime, Minister, Benjamin, Netanyahu...</td>\n",
       "      <td>[23, 24, 25, 26, 27, 28]</td>\n",
       "      <td>withdraw from the Iran nuclear deal</td>\n",
       "      <td>9</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>EVENT_KriYzG6R</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>watch</td>\n",
       "      <td>watched</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>9_RR_49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[the, regime, had, allegedly, hid, its, nuclea...</td>\n",
       "      <td>[22, 23, 24]</td>\n",
       "      <td>Netanyahu's presentation</td>\n",
       "      <td>9</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Presentation</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>MISC_DvVtbYoH</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>9_RR_49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[Netanyahu, said, ., Israel, uncovered, secret...</td>\n",
       "      <td>[39, 40, 41]</td>\n",
       "      <td>a US exit</td>\n",
       "      <td>9</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Reaction to IRN deal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1173 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          coref_chain                  code mention_ner mention_head_pos  \\\n",
       "3      EVENT_Am92KUuK        PRK USA Summit      PERSON             NOUN   \n",
       "4     ACTION_pgyA4XU5           Trip to PRK      PERSON             NOUN   \n",
       "5     ACTION_6dhrjKQJ           Trip to PRK      PERSON             NOUN   \n",
       "9      EVENT_LH6yuqwW        PRK USA Summit           O             NOUN   \n",
       "10     EVENT_8Lu6Sue9        PRK USA Summit           O             VERB   \n",
       "...               ...                   ...         ...              ...   \n",
       "3798    MISC_p7QxVGw6  IRN nuclear activity           O             VERB   \n",
       "3812   EVENT_YhnKwFRg          Presentation      PERSON             VERB   \n",
       "3813    MISC_AwtnKuR6  Reaction to IRN deal           O             VERB   \n",
       "3815   EVENT_KriYzG6R          Presentation      PERSON             VERB   \n",
       "3818    MISC_DvVtbYoH  Reaction to IRN deal           O             VERB   \n",
       "\n",
       "     mention_head_lemma mention_head            coref_link doc_id_full  \\\n",
       "3               meeting      meeting        PRK USA Summit       0_L_0   \n",
       "4                leader       leader           Trip to PRK       0_L_0   \n",
       "5               meeting      meeting           Trip to PRK       0_L_0   \n",
       "9               meeting      meeting        PRK USA Summit       0_L_0   \n",
       "10               allude      alluded        PRK USA Summit       0_L_0   \n",
       "...                 ...          ...                   ...         ...   \n",
       "3798                say         said  IRN nuclear activity     9_RR_49   \n",
       "3812               come         came          Presentation     9_RR_49   \n",
       "3813           withdraw     withdraw  Reaction to IRN deal     9_RR_49   \n",
       "3815              watch      watched          Presentation     9_RR_49   \n",
       "3818                say         said  Reaction to IRN deal     9_RR_49   \n",
       "\n",
       "      doc_id pol_direction  ...  mention_full_type  score sent_id  \\\n",
       "3        0.0             L  ...              EVENT   -1.0     1.0   \n",
       "4        0.0             L  ...             ACTION   -1.0     1.0   \n",
       "5        0.0             L  ...             ACTION   -1.0     1.0   \n",
       "9        0.0             L  ...              EVENT   -1.0     2.0   \n",
       "10       0.0             L  ...              EVENT   -1.0     2.0   \n",
       "...      ...           ...  ...                ...    ...     ...   \n",
       "3798     9.0            RR  ...               MISC   -1.0     3.0   \n",
       "3812     9.0            RR  ...              EVENT   -1.0    11.0   \n",
       "3813     9.0            RR  ...               MISC   -1.0    11.0   \n",
       "3815     9.0            RR  ...              EVENT   -1.0    12.0   \n",
       "3818     9.0            RR  ...               MISC   -1.0    13.0   \n",
       "\n",
       "                                        mention_context  \\\n",
       "3     [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "4     [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "5     [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "9     [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "10    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "...                                                 ...   \n",
       "3798  [U.S., intelligence, reportedly, confirmed, th...   \n",
       "3812  [U.S., intelligence, reportedly, confirmed, th...   \n",
       "3813  [Israeli, Prime, Minister, Benjamin, Netanyahu...   \n",
       "3815  [the, regime, had, allegedly, hid, its, nuclea...   \n",
       "3818  [Netanyahu, said, ., Israel, uncovered, secret...   \n",
       "\n",
       "                         tokens_number  \\\n",
       "3                             [31, 32]   \n",
       "4                 [11, 12, 13, 14, 15]   \n",
       "5     [25, 26, 27, 28, 29, 30, 31, 32]   \n",
       "9                             [44, 45]   \n",
       "10        [43, 44, 45, 46, 47, 48, 49]   \n",
       "...                                ...   \n",
       "3798                  [13, 14, 15, 16]   \n",
       "3812                         [0, 1, 2]   \n",
       "3813          [23, 24, 25, 26, 27, 28]   \n",
       "3815                      [22, 23, 24]   \n",
       "3818                      [39, 40, 41]   \n",
       "\n",
       "                                      tokens_str  topic_id coref_type  \\\n",
       "3                                 summit meeting         0     STRICT   \n",
       "4                        to meet with its leader         0     STRICT   \n",
       "5     to lay the groundwork for a summit meeting         0     STRICT   \n",
       "9                              potential meeting         0     STRICT   \n",
       "10        a potential meeting of the two leaders         0     STRICT   \n",
       "...                                          ...       ...        ...   \n",
       "3798                   a nuclear weapons program         9     STRICT   \n",
       "3812                    Netanyahu's presentation         9     STRICT   \n",
       "3813         withdraw from the Iran nuclear deal         9     STRICT   \n",
       "3815                    Netanyahu's presentation         9     STRICT   \n",
       "3818                                   a US exit         9     STRICT   \n",
       "\n",
       "               description mention_head_lemma_uniques  \n",
       "3           PRK USA Summit                        1.0  \n",
       "4              Trip to PRK                        1.0  \n",
       "5              Trip to PRK                        1.0  \n",
       "9           PRK USA Summit                        2.0  \n",
       "10          PRK USA Summit                        1.0  \n",
       "...                    ...                        ...  \n",
       "3798  IRN nuclear activity                        2.0  \n",
       "3812          Presentation                        3.0  \n",
       "3813  Reaction to IRN deal                        1.0  \n",
       "3815          Presentation                        3.0  \n",
       "3818  Reaction to IRN deal                        1.0  \n",
       "\n",
       "[1173 rows x 24 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entities = pd.DataFrame()\n",
    "df_events = pd.DataFrame()\n",
    "\n",
    "for i, row in df_final.iterrows():\n",
    "    if row[\"mention_type\"] not in events:\n",
    "        df_entities = df_entities.append(row)\n",
    "    else:\n",
    "        df_events = df_events.append(row)\n",
    "\n",
    "df_entities.drop(columns= [\"tokens_amount\"])\n",
    "df_events.drop(columns= [\"tokens_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./entity_mentions.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(ujson.dumps(df_entities.to_dict('index'), indent=4, ensure_ascii=False, escape_forward_slashes=False))\n",
    "\n",
    "with open(f'./event_mentions.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(ujson.dumps(df_events.to_dict('index'), indent=4, ensure_ascii=False, escape_forward_slashes=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also make a all_mentions csv file\n",
    "df_all_mentions = df_final.drop(columns=[\"is_continuous\", \"is_singleton\", \"score\", \"sent_id\", \"tokens_number\", \"topic_id\", \"coref_type\", \"mention_context\", \"mention_ner\", \"mention_head_pos\", \"mention_head_lemma\", \"coref_link\", \"tokens_amount\"]).rename(index = df_final.mention_id)\n",
    "df_all_mentions = df_all_mentions.drop(columns = [\"mention_id\"])\n",
    "df_all_mentions.to_csv(path_or_buf=\"all_mentions.csv\", sep=\",\", na_rep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>pol_direction</th>\n",
       "      <th>mention_type</th>\n",
       "      <th>mention_full_type</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>description</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_L_0_1_6</th>\n",
       "      <td>COUNTRY_ZVbotWQj</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_L_0_1_14</th>\n",
       "      <td>COUNTRY_fjep4p8J</td>\n",
       "      <td>PRK</td>\n",
       "      <td>meet</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>PRK</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_L_0_1_9</th>\n",
       "      <td>COUNTRY_AQa6Civp</td>\n",
       "      <td>USA</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_L_0_1_35</th>\n",
       "      <td>EVENT_Am92KUuK</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>meeting</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_L_0_1_19</th>\n",
       "      <td>ACTION_pgyA4XU5</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>leader</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coref_chain            code mention_head doc_id_full  doc_id  \\\n",
       "0_L_0_1_6   COUNTRY_ZVbotWQj             USA       Pompeo       0_L_0       0   \n",
       "0_L_0_1_14  COUNTRY_fjep4p8J             PRK         meet       0_L_0       0   \n",
       "0_L_0_1_9   COUNTRY_AQa6Civp             USA   dispatched       0_L_0       0   \n",
       "0_L_0_1_35    EVENT_Am92KUuK  PRK USA Summit      meeting       0_L_0       0   \n",
       "0_L_0_1_19   ACTION_pgyA4XU5     Trip to PRK       leader       0_L_0       0   \n",
       "\n",
       "           pol_direction mention_type mention_full_type  \\\n",
       "0_L_0_1_6              L      COUNTRY           COUNTRY   \n",
       "0_L_0_1_14             L      COUNTRY           COUNTRY   \n",
       "0_L_0_1_9              L      COUNTRY           COUNTRY   \n",
       "0_L_0_1_35             L        EVENT             EVENT   \n",
       "0_L_0_1_19             L       ACTION            ACTION   \n",
       "\n",
       "                         tokens_str     description  \\\n",
       "0_L_0_1_6           C.I.A. director             USA   \n",
       "0_L_0_1_14              North Korea             PRK   \n",
       "0_L_0_1_9                    C.I.A.             USA   \n",
       "0_L_0_1_35           summit meeting  PRK USA Summit   \n",
       "0_L_0_1_19  to meet with its leader     Trip to PRK   \n",
       "\n",
       "            mention_head_lemma_uniques  \n",
       "0_L_0_1_6                            1  \n",
       "0_L_0_1_14                          31  \n",
       "0_L_0_1_9                            2  \n",
       "0_L_0_1_35                           1  \n",
       "0_L_0_1_19                           1  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_full_type</th>\n",
       "      <th>score</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNTRY_ZVbotWQj</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COUNTRY_fjep4p8J</td>\n",
       "      <td>PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COUNTRY_AQa6Civp</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVENT_Am92KUuK</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[31, 32]</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTION_pgyA4XU5</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        coref_chain            code  tokens_amount mention_ner  \\\n",
       "0  COUNTRY_ZVbotWQj             USA           1650      PERSON   \n",
       "1  COUNTRY_fjep4p8J             PRK           1650         GPE   \n",
       "2  COUNTRY_AQa6Civp             USA           1650      PERSON   \n",
       "3    EVENT_Am92KUuK  PRK USA Summit           1650      PERSON   \n",
       "4   ACTION_pgyA4XU5     Trip to PRK           1650      PERSON   \n",
       "\n",
       "  mention_head_pos mention_head_lemma mention_head      coref_link  \\\n",
       "0            PROPN             Pompeo       Pompeo             USA   \n",
       "1             VERB               meet         meet             PRK   \n",
       "2             VERB           dispatch   dispatched             USA   \n",
       "3             NOUN            meeting      meeting  PRK USA Summit   \n",
       "4             NOUN             leader       leader     Trip to PRK   \n",
       "\n",
       "  doc_id_full  doc_id  ... mention_full_type  score  sent_id  \\\n",
       "0       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "1       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "2       0_L_0       0  ...           COUNTRY     -1        1   \n",
       "3       0_L_0       0  ...             EVENT     -1        1   \n",
       "4       0_L_0       0  ...            ACTION     -1        1   \n",
       "\n",
       "                                     mention_context         tokens_number  \\\n",
       "0  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...                [4, 5]   \n",
       "1  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...               [9, 10]   \n",
       "2  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...                   [4]   \n",
       "3  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...              [31, 32]   \n",
       "4  [WEST, PALM, BEACH, ,, Fla., —, President, Tru...  [11, 12, 13, 14, 15]   \n",
       "\n",
       "                tokens_str  topic_id  coref_type     description  \\\n",
       "0          C.I.A. director         0      STRICT             USA   \n",
       "1              North Korea         0      STRICT             PRK   \n",
       "2                   C.I.A.         0      STRICT             USA   \n",
       "3           summit meeting         0      STRICT  PRK USA Summit   \n",
       "4  to meet with its leader         0      STRICT     Trip to PRK   \n",
       "\n",
       "  mention_head_lemma_uniques  \n",
       "0                          1  \n",
       "1                         31  \n",
       "2                          2  \n",
       "3                          1  \n",
       "4                          1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [03:22,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "#generate conll file\n",
    "\n",
    "df_conll = pd.DataFrame(columns = {\"doc_identifier\", \"sent_id\", \"token_id\", \"text\", \"reference\"})\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    for sentence_id, sentence in enumerate(row[\"doc\"].sents):\n",
    "        for token_id, token in enumerate(sentence):\n",
    "            if token.text != \"\\n\":\n",
    "                doc_id_full = row[\"source_domain\"]\n",
    "                doc_unique_id = doc_id_full+\"_\"+str(i)\n",
    "\n",
    "                df_conll = df_conll.append( {\"doc_identifier\": doc_unique_id, \"sent_id\": sentence_id, \"token_id\": token_id, \"text\": token.text, \"reference\": \"\"}, ignore_index=True)\n",
    "    #if i>=10:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47264 df_conll rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47264it [3:31:21,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "added_corefs = []\n",
    "\n",
    "print(\"Processing \" + str(len(df_conll)) + \" df_conll rows...\")\n",
    "\n",
    "for i, row_conll in tqdm(df_conll.iterrows()):\n",
    "    amount_of_added_mentions = 0\n",
    "    for j, row_final in df_final.iterrows():\n",
    "        tokens_number = row_final[\"tokens_number\"]\n",
    "        token_id = row_conll[\"token_id\"]\n",
    "        sent_id = row_conll[\"sent_id\"]\n",
    "        \n",
    "        if row_conll[\"doc_identifier\"] == row_final[\"doc_id_full\"] and row_final[\"sent_id\"] == sent_id and token_id in tokens_number:\n",
    "            added_corefs.append(row_final[\"coref_chain\"])\n",
    "            coref_chain = row_final[\"coref_chain\"]\n",
    "            \n",
    "            #determine the amount of already added corefs with the id (to get the brackets correct)\n",
    "            coref_count = added_corefs.count(coref_chain)\n",
    "\n",
    "            #add a string based on how many or if all corefs have been added\n",
    "            if coref_count == 1 and len(tokens_number) == 1:    #first and only coref token\n",
    "                df_conll.at[i, \"reference\"] = row_conll[\"reference\"] + \"| (\" + row_final[\"coref_chain\"] + \")\"\n",
    "            elif coref_count == 1:    #first of multiple coref token\n",
    "                df_conll.at[i, \"reference\"] = row_conll[\"reference\"] + \"| (\" + row_final[\"coref_chain\"]\n",
    "            elif coref_count == len(tokens_number):   #last coref token\n",
    "                df_conll.at[i, \"reference\"] = row_conll[\"reference\"] + \"| \" + row_final[\"coref_chain\"] + \")\"\n",
    "            #else: #middle coref tokens\n",
    "               # df_conll.at[i, \"reference\"] = row_conll[\"reference\"] + \"| \" + row_final[\"coref_chain\"]\n",
    "    \n",
    "    if row_conll[\"reference\"] != \"\":\n",
    "        if row_conll[\"reference\"][0] == \"|\":    #remove first | from string\n",
    "            df_conll.at[i, \"reference\"] = row_conll[\"reference\"][2:]\n",
    "    #if i>1000:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conll.reset_index(drop=True,inplace=True)\n",
    "\n",
    "with open(f'./conll_test.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(ujson.dumps(df_conll.to_dict('index'), indent=4, ensure_ascii=False, escape_forward_slashes=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47264it [00:17, 2691.38it/s]\n"
     ]
    }
   ],
   "source": [
    "#Make the conll file from the dataframe\n",
    "\n",
    "dfAsString = \"\"\n",
    "previous_sentence = df_conll[\"sent_id\"][0]\n",
    "previous_doc =  df_conll[\"doc_identifier\"][0]\n",
    "\n",
    "with open(f'./newswcl50.conll', 'w', encoding='utf-8') as f:\n",
    "    for i, row in tqdm(df_conll.iterrows()):\n",
    "        #line breaks at new sentences and #header and #end\n",
    "        if i == 0:\n",
    "            dfAsString = dfAsString + \"#begin document \" + row[\"doc_identifier\"] + \"; part 000\" + \"\\n\"\n",
    "        if row[\"sent_id\"] != previous_sentence:\n",
    "            dfAsString = dfAsString + \"\\n\"\n",
    "        if row[\"doc_identifier\"] != previous_doc:\n",
    "            dfAsString = dfAsString + \"#end document\" + \"\\n\"\n",
    "            dfAsString = dfAsString + \"#begin document \" + row[\"doc_identifier\"] + \"; part 000\" + \"\\n\"\n",
    "\n",
    "        if row['reference'] != \"\":\n",
    "            dfAsString = dfAsString + row['doc_identifier'] + '\\t' + str(row['sent_id']) + '\\t' + str(row['token_id']) + '\\t' + row['text'] + '\\t' + row['reference'] + \"\\n\"\n",
    "        else:\n",
    "            dfAsString = dfAsString + row['doc_identifier'] + '\\t' + str(row['sent_id']) + '\\t' + str(row['token_id']) + '\\t' + row['text'] + '\\t' + \"-\" + \"\\n\"\n",
    "        previous_sentence = row[\"sent_id\"]\n",
    "        previous_doc = row[\"doc_identifier\"]\n",
    "    f.write(dfAsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_identifier</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>reference</th>\n",
       "      <th>token_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>WEST</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>PALM</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>BEACH</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fla.</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_identifier sent_id   text reference token_id\n",
       "0          0_L_0       0   WEST                  0\n",
       "1          0_L_0       0   PALM                  1\n",
       "2          0_L_0       0  BEACH                  2\n",
       "3          0_L_0       0      ,                  3\n",
       "4          0_L_0       0   Fla.                  4"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>code</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th>mention_ner</th>\n",
       "      <th>mention_head_pos</th>\n",
       "      <th>mention_head_lemma</th>\n",
       "      <th>mention_head</th>\n",
       "      <th>coref_link</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>...</th>\n",
       "      <th>mention_full_type</th>\n",
       "      <th>score</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>mention_context</th>\n",
       "      <th>tokens_number</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>coref_type</th>\n",
       "      <th>description</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNTRY_ZVbotWQj</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>Pompeo</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>C.I.A. director</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COUNTRY_fjep4p8J</td>\n",
       "      <td>PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>GPE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COUNTRY_AQa6Civp</td>\n",
       "      <td>USA</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>dispatched</td>\n",
       "      <td>USA</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>C.I.A.</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVENT_Am92KUuK</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[31, 32]</td>\n",
       "      <td>summit meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTION_pgyA4XU5</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1650</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>0_L_0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>ACTION</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[WEST, PALM, BEACH, ,, Fla., —, President, Tru...</td>\n",
       "      <td>[11, 12, 13, 14, 15]</td>\n",
       "      <td>to meet with its leader</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Trip to PRK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>MISC_C6hQiKRF</td>\n",
       "      <td>Denuclearization</td>\n",
       "      <td>2177</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>saying</td>\n",
       "      <td>Denuclearization</td>\n",
       "      <td>0_LL_1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>[the, United, States, and, South, Korea, ., En...</td>\n",
       "      <td>[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]</td>\n",
       "      <td>to engage in a process, headed toward an ambig...</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>Denuclearization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>EVENT_SiVFtQe6</td>\n",
       "      <td>PRK KOR Meeting</td>\n",
       "      <td>2177</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>report</td>\n",
       "      <td>reported</td>\n",
       "      <td>PRK KOR Meeting</td>\n",
       "      <td>0_LL_1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>[House, has, said, the, talks, are, supposed, ...</td>\n",
       "      <td>[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...</td>\n",
       "      <td>upcoming meeting on April 27 with South Korean...</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK KOR Meeting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>COUNTRY_Lt4VmgWk</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2177</td>\n",
       "      <td>GPE</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>0_LL_1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>18</td>\n",
       "      <td>[Tuesday, that, five, locations, were, being, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>CHN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>COUNTRY_D44f7huw</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2177</td>\n",
       "      <td>NORP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>say</td>\n",
       "      <td>said</td>\n",
       "      <td>CHN</td>\n",
       "      <td>0_LL_1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>-1</td>\n",
       "      <td>19</td>\n",
       "      <td>[said, he, believed, \", there, 's, a, lot, of,...</td>\n",
       "      <td>[23]</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>EVENT_fLG6yAZy</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>2177</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "      <td>confirm</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>0_LL_1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>[., \\n, \", We, 'll, see, what, happens, ,, as,...</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>the meeting</td>\n",
       "      <td>0</td>\n",
       "      <td>STRICT</td>\n",
       "      <td>PRK USA Summit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          coref_chain              code  tokens_amount mention_ner  \\\n",
       "0    COUNTRY_ZVbotWQj               USA           1650      PERSON   \n",
       "1    COUNTRY_fjep4p8J               PRK           1650         GPE   \n",
       "2    COUNTRY_AQa6Civp               USA           1650      PERSON   \n",
       "3      EVENT_Am92KUuK    PRK USA Summit           1650      PERSON   \n",
       "4     ACTION_pgyA4XU5       Trip to PRK           1650      PERSON   \n",
       "..                ...               ...            ...         ...   \n",
       "145     MISC_C6hQiKRF  Denuclearization           2177      PERSON   \n",
       "146    EVENT_SiVFtQe6   PRK KOR Meeting           2177      PERSON   \n",
       "147  COUNTRY_Lt4VmgWk               CHN           2177         GPE   \n",
       "148  COUNTRY_D44f7huw               CHN           2177        NORP   \n",
       "149    EVENT_fLG6yAZy    PRK USA Summit           2177           O   \n",
       "\n",
       "    mention_head_pos mention_head_lemma mention_head        coref_link  \\\n",
       "0              PROPN             Pompeo       Pompeo               USA   \n",
       "1               VERB               meet         meet               PRK   \n",
       "2               VERB           dispatch   dispatched               USA   \n",
       "3               NOUN            meeting      meeting    PRK USA Summit   \n",
       "4               NOUN             leader       leader       Trip to PRK   \n",
       "..               ...                ...          ...               ...   \n",
       "145             VERB                say       saying  Denuclearization   \n",
       "146             VERB             report     reported   PRK KOR Meeting   \n",
       "147            PROPN              China        China               CHN   \n",
       "148             VERB                say         said               CHN   \n",
       "149             VERB            confirm    confirmed    PRK USA Summit   \n",
       "\n",
       "    doc_id_full  doc_id  ... mention_full_type  score  sent_id  \\\n",
       "0         0_L_0       0  ...           COUNTRY     -1        1   \n",
       "1         0_L_0       0  ...           COUNTRY     -1        1   \n",
       "2         0_L_0       0  ...           COUNTRY     -1        1   \n",
       "3         0_L_0       0  ...             EVENT     -1        1   \n",
       "4         0_L_0       0  ...            ACTION     -1        1   \n",
       "..          ...     ...  ...               ...    ...      ...   \n",
       "145      0_LL_1       0  ...              MISC     -1       16   \n",
       "146      0_LL_1       0  ...             EVENT     -1       17   \n",
       "147      0_LL_1       0  ...           COUNTRY     -1       18   \n",
       "148      0_LL_1       0  ...           COUNTRY     -1       19   \n",
       "149      0_LL_1       0  ...             EVENT     -1       20   \n",
       "\n",
       "                                       mention_context  \\\n",
       "0    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "1    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "2    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "3    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "4    [WEST, PALM, BEACH, ,, Fla., —, President, Tru...   \n",
       "..                                                 ...   \n",
       "145  [the, United, States, and, South, Korea, ., En...   \n",
       "146  [House, has, said, the, talks, are, supposed, ...   \n",
       "147  [Tuesday, that, five, locations, were, being, ...   \n",
       "148  [said, he, believed, \", there, 's, a, lot, of,...   \n",
       "149  [., \\n, \", We, 'll, see, what, happens, ,, as,...   \n",
       "\n",
       "                                         tokens_number  \\\n",
       "0                                               [4, 5]   \n",
       "1                                              [9, 10]   \n",
       "2                                                  [4]   \n",
       "3                                             [31, 32]   \n",
       "4                                 [11, 12, 13, 14, 15]   \n",
       "..                                                 ...   \n",
       "145   [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]   \n",
       "146  [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...   \n",
       "147                                                [6]   \n",
       "148                                               [23]   \n",
       "149                                           [12, 13]   \n",
       "\n",
       "                                            tokens_str  topic_id  coref_type  \\\n",
       "0                                      C.I.A. director         0      STRICT   \n",
       "1                                          North Korea         0      STRICT   \n",
       "2                                               C.I.A.         0      STRICT   \n",
       "3                                       summit meeting         0      STRICT   \n",
       "4                              to meet with its leader         0      STRICT   \n",
       "..                                                 ...       ...         ...   \n",
       "145  to engage in a process, headed toward an ambig...         0      STRICT   \n",
       "146  upcoming meeting on April 27 with South Korean...         0      STRICT   \n",
       "147                                              China         0      STRICT   \n",
       "148                                            Chinese         0      STRICT   \n",
       "149                                        the meeting         0      STRICT   \n",
       "\n",
       "          description mention_head_lemma_uniques  \n",
       "0                 USA                          1  \n",
       "1                 PRK                         31  \n",
       "2                 USA                          2  \n",
       "3      PRK USA Summit                          1  \n",
       "4         Trip to PRK                          1  \n",
       "..                ...                        ...  \n",
       "145  Denuclearization                          1  \n",
       "146   PRK KOR Meeting                          1  \n",
       "147               CHN                          4  \n",
       "148               CHN                          1  \n",
       "149    PRK USA Summit                          5  \n",
       "\n",
       "[150 rows x 25 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1650\n",
      "1       1650\n",
      "2       1650\n",
      "3       1650\n",
      "4       1650\n",
      "        ... \n",
      "3815    3736\n",
      "3816    3736\n",
      "3817    3736\n",
      "3818    3736\n",
      "3819    3736\n",
      "Name: tokens_amount, Length: 3820, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final[\"tokens_amount\"])\n",
    "#generate a dataset summary\n",
    "\n",
    "df_summary = df_final.groupby(by = [\"doc_id\"], as_index=False).agg(\n",
    "    {\n",
    "        'doc_id_full': [\"nunique\"],\n",
    "        'coref_chain': [\"nunique\"],\n",
    "        'tokens_amount': [\"max\"],   \n",
    "        'mention_full_type': [lambda x: x[x.str.contains('EVENT|MISC|ACTION')].count(), lambda x: x[~x.str.contains('EVENT|MISC|ACTION')].count()],    #event_mentions and entity_mentions\n",
    "        'is_singleton': [\"sum\"],\n",
    "        'mention_head_lemma_uniques': [\"mean\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_id_full</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>tokens_amount</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mention_full_type</th>\n",
       "      <th>is_singleton</th>\n",
       "      <th>mention_head_lemma_uniques</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>nunique</th>\n",
       "      <th>max</th>\n",
       "      <th>&lt;lambda_0&gt;</th>\n",
       "      <th>&lt;lambda_1&gt;</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>350</td>\n",
       "      <td>4485</td>\n",
       "      <td>134</td>\n",
       "      <td>216</td>\n",
       "      <td>178</td>\n",
       "      <td>6.917143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>225</td>\n",
       "      <td>5088</td>\n",
       "      <td>8</td>\n",
       "      <td>217</td>\n",
       "      <td>151</td>\n",
       "      <td>3.595556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>425</td>\n",
       "      <td>4626</td>\n",
       "      <td>187</td>\n",
       "      <td>238</td>\n",
       "      <td>232</td>\n",
       "      <td>5.404706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>530</td>\n",
       "      <td>5165</td>\n",
       "      <td>378</td>\n",
       "      <td>152</td>\n",
       "      <td>269</td>\n",
       "      <td>7.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>355</td>\n",
       "      <td>6098</td>\n",
       "      <td>56</td>\n",
       "      <td>299</td>\n",
       "      <td>226</td>\n",
       "      <td>13.529577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id doc_id_full coref_chain tokens_amount mention_full_type             \\\n",
       "             nunique     nunique           max        <lambda_0> <lambda_1>   \n",
       "0      0           5         350          4485               134        216   \n",
       "1      1           5         225          5088                 8        217   \n",
       "2      2           5         425          4626               187        238   \n",
       "3      3           5         530          5165               378        152   \n",
       "4      4           5         355          6098                56        299   \n",
       "\n",
       "  is_singleton mention_head_lemma_uniques  \n",
       "           sum                       mean  \n",
       "0          178                   6.917143  \n",
       "1          151                   3.595556  \n",
       "2          232                   5.404706  \n",
       "3          269                   7.754717  \n",
       "4          226                  13.529577  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (9) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9728/1205174532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"doc_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"files\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"chains\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tokens\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"event_mentions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"entity_mentions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"is_singleton\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"avg_unique_head_lemmas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_summary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lexical_diversity\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_total_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cdcr\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cdcr\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cdcr\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cdcr\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (9) does not match length of index (10)"
     ]
    }
   ],
   "source": [
    "df_summary.columns = df_summary.columns.droplevel(0)\n",
    "df_summary.columns = [\"doc_id\", \"files\", \"chains\", \"tokens\", \"event_mentions\", \"entity_mentions\", \"is_singleton\", \"avg_unique_head_lemmas\"]\n",
    "df_summary[\"lexical_diversity\"] = pd_total_list\n",
    "\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>chains</th>\n",
       "      <th>tokens</th>\n",
       "      <th>event_mentions</th>\n",
       "      <th>entity_mentions</th>\n",
       "      <th>is_singleton</th>\n",
       "      <th>avg_unique_head_lemmas</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>980</td>\n",
       "      <td>4485</td>\n",
       "      <td>163</td>\n",
       "      <td>817</td>\n",
       "      <td>648</td>\n",
       "      <td>16.356122</td>\n",
       "      <td>8.754916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>449</td>\n",
       "      <td>5088</td>\n",
       "      <td>11</td>\n",
       "      <td>438</td>\n",
       "      <td>313</td>\n",
       "      <td>7.260579</td>\n",
       "      <td>9.312849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1092</td>\n",
       "      <td>4626</td>\n",
       "      <td>222</td>\n",
       "      <td>870</td>\n",
       "      <td>713</td>\n",
       "      <td>13.658425</td>\n",
       "      <td>10.514398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1123</td>\n",
       "      <td>5165</td>\n",
       "      <td>719</td>\n",
       "      <td>404</td>\n",
       "      <td>616</td>\n",
       "      <td>10.330365</td>\n",
       "      <td>31.707820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1544</td>\n",
       "      <td>6098</td>\n",
       "      <td>67</td>\n",
       "      <td>1477</td>\n",
       "      <td>1232</td>\n",
       "      <td>29.992876</td>\n",
       "      <td>10.863775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   files  chains  tokens  event_mentions  entity_mentions  is_singleton  \\\n",
       "0      5     980    4485             163              817           648   \n",
       "1      5     449    5088              11              438           313   \n",
       "2      5    1092    4626             222              870           713   \n",
       "3      5    1123    5165             719              404           616   \n",
       "4      5    1544    6098              67             1477          1232   \n",
       "\n",
       "   avg_unique_head_lemmas  lexical_diversity  \n",
       "0               16.356122           8.754916  \n",
       "1                7.260579           9.312849  \n",
       "2               13.658425          10.514398  \n",
       "3               10.330365          31.707820  \n",
       "4               29.992876          10.863775  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_summary.reset_index(drop=True,inplace=True)\n",
    "df_summary.rename(index = df_summary[\"doc_id\"], inplace = True)\n",
    "df_summary = df_summary.drop(columns= [\"doc_id\"] )\n",
    "\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv(path_or_buf=\"dataset_summary.csv\", sep=\",\", na_rep=\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21ab713a94b9dff8ceab4d966c04cbd434fb99e8b3685c982045bb942eef746a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('kcc': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
